{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "gen = torch.manual_seed(2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Data is expected to be located in a folder in separate files with .npy format. This is audio data encoded in Numpy array format which is loaded directly. The dataloader calculates MFCC coefficients for each of the audio files. The labels and file locations are read from a `.csv` datafile.\n",
    "\n",
    "Additionally, these files are expected to be of a constant length and sample rate. This size is entered manually below; this was run with audio of 15 seconds length and 22050 sample rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoundDataset(Dataset):\n",
    "    def __init__(self, datafile, data_dir, transform = None):\n",
    "        self.data_dir = data_dir\n",
    "        self.data_file = pd.read_csv(datafile)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_file)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dat_file = self.data_file.iloc[idx].filepath\n",
    "        dat_file = os.path.join(self.data_dir, dat_file)\n",
    "        label = self.data_file.iloc[idx].multi_classification\n",
    "        audio_np = np.load(dat_file, allow_pickle=True)\n",
    "\n",
    "        if self.transform:\n",
    "            audio_np = self.transform(audio_np)\n",
    "        return audio_np, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFCC_Transform:\n",
    "    def __init__(self, n_mfcc_coeffs):\n",
    "        self.n_mfcc_coeffs = n_mfcc_coeffs\n",
    "        self.sr = 22050\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        return librosa.feature.mfcc(y=sample, sr=self.sr, n_mfcc=self.n_mfcc_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_trans = MFCC_Transform(70)\n",
    "dataset = SoundDataset(\"multi_data_description.csv\", \"new_np_data/\", transform=mfcc_trans)\n",
    "train, test, validate = torch.utils.data.random_split(dataset, [0.8, 0.1, 0.1], generator=gen)\n",
    "train_dataloader = DataLoader(train, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(test, batch_size=128, shuffle=True)\n",
    "validation_dataloader = DataLoader(validate, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Architecture\n",
    "The architecture below uses a hybrid CNN / GRU architecture. First, CNN layers are applied with batch normalisation and dropout, to attempt to extract useful features from the audio data. \n",
    "\n",
    "The outputs from the CNN layers are fed to the GRU layer, in order to extract time-series patterns from the CNN layers.\n",
    "\n",
    "Then, the GRU outputs are consolidated with a final set of Linear layers, to produce class output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_GRU(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(CNN_GRU, self).__init__()\n",
    "\n",
    "        if len(input_size) != 2:\n",
    "            raise Exception(\"Input should have 2 axes\")\n",
    "        self.in_x, self.in_y = input_size\n",
    "        self.leakyRelu = torch.nn.LeakyReLU(negative_slope=0.2)\n",
    "        # self.maxpool = F.max_pool2d\n",
    "\n",
    "        kernel1 = 16\n",
    "        self.conv1 = torch.nn.Conv2d(1, 32, kernel_size = kernel1)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(32)\n",
    "        self.dropout1 = torch.nn.Dropout2d(0.4)\n",
    "\n",
    "        kernel2 = 8\n",
    "        self.conv2 = torch.nn.Conv2d(32, 16, kernel_size = kernel2)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(16)\n",
    "        self.dropout2 = torch.nn.Dropout2d(0.4)\n",
    "\n",
    "        kernel3 = 4\n",
    "        self.conv3 = torch.nn.Conv2d(16, 1, kernel_size = kernel3)\n",
    "        self.bn3 = torch.nn.BatchNorm2d(1)\n",
    "        self.dropout3 = torch.nn.Dropout2d(0.4)\n",
    "\n",
    "\n",
    "        size_x = self.in_x - (kernel1 - 1) - (kernel2 - 1) - (kernel3 - 1)\n",
    "        size_y = self.in_y - (kernel1 - 1) - (kernel2 - 1) - (kernel3 - 1)\n",
    "        self.hidden_size = 64\n",
    "        self.gru = torch.nn.GRU(input_size=size_x, hidden_size=self.hidden_size, batch_first=True)\n",
    "        self.seq_len = size_y\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(in_features=self.seq_len*self.hidden_size, out_features=256)\n",
    "        self.sig_activ = torch.nn.Sigmoid()\n",
    "        self.fc2 = torch.nn.Linear(in_features=256, out_features=32)\n",
    "        self.fc3 = torch.nn.Linear(in_features=32, out_features=output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        if len(x.shape) == 3:\n",
    "            x = x.unsqueeze(0)\n",
    "        x = self.bn1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        x = self.leakyRelu(x)\n",
    "        x = x.view(x.size(0), x.size(3), -1)  # batch, seq_len, features\n",
    "        x, _ = self.gru(x)\n",
    "        x = x.reshape(-1, self.hidden_size*self.seq_len)\n",
    "        # x = x.view(x.size(0), -1)  # batch, seq_len, features\n",
    "        x = self.fc1(x)\n",
    "        x = self.sig_activ(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sig_activ(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sig_activ(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, testloader, num_epochs, lr):\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        loss = 0\n",
    "        for inputs, labels in dataloader:\n",
    "            labels = labels.to(device)\n",
    "            inputs = inputs.unsqueeze(1).to(device)\n",
    "            # print(inputs.shape)\n",
    "            outputs = model(inputs).to(device)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "        # loss /= len(dataloader)\n",
    "        # loss.backward()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        # Test accuracy after each epoch\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in testloader:\n",
    "                # calculate outputs by running images through the network\n",
    "                inputs = inputs.unsqueeze(1).to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs).to(device)\n",
    "                # the class with the highest energy is what we choose as prediction\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f'Accuracy: {100 * correct / total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_GRU(\n",
      "  (leakyRelu): LeakyReLU(negative_slope=0.2)\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(16, 16), stride=(1, 1))\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout1): Dropout2d(p=0.4, inplace=False)\n",
      "  (conv2): Conv2d(32, 16, kernel_size=(8, 8), stride=(1, 1))\n",
      "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout2): Dropout2d(p=0.4, inplace=False)\n",
      "  (conv3): Conv2d(16, 1, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (bn3): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout3): Dropout2d(p=0.4, inplace=False)\n",
      "  (gru): GRU(45, 64, batch_first=True)\n",
      "  (fc1): Linear(in_features=39744, out_features=256, bias=True)\n",
      "  (sig_activ): Sigmoid()\n",
      "  (fc2): Linear(in_features=256, out_features=32, bias=True)\n",
      "  (fc3): Linear(in_features=32, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn_gru = CNN_GRU((70, 646), 7).to(device)\n",
    "print(cnn_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 1.6096\n",
      "Accuracy: 45.0 %\n",
      "Epoch 2/30, Loss: 1.5531\n",
      "Accuracy: 45.0 %\n",
      "Epoch 3/30, Loss: 1.5061\n",
      "Accuracy: 45.0 %\n",
      "Epoch 4/30, Loss: 1.4781\n",
      "Accuracy: 45.0 %\n",
      "Epoch 5/30, Loss: 2.0201\n",
      "Accuracy: 45.0 %\n",
      "Epoch 6/30, Loss: 1.3927\n",
      "Accuracy: 45.0 %\n",
      "Epoch 7/30, Loss: 1.7257\n",
      "Accuracy: 45.0 %\n",
      "Epoch 8/30, Loss: 2.1213\n",
      "Accuracy: 45.0 %\n",
      "Epoch 9/30, Loss: 1.9582\n",
      "Accuracy: 45.0 %\n",
      "Epoch 10/30, Loss: 1.7509\n",
      "Accuracy: 45.0 %\n",
      "Epoch 11/30, Loss: 1.3844\n",
      "Accuracy: 45.0 %\n",
      "Epoch 12/30, Loss: 1.9433\n",
      "Accuracy: 45.0 %\n",
      "Epoch 13/30, Loss: 1.4883\n",
      "Accuracy: 45.0 %\n",
      "Epoch 14/30, Loss: 1.4574\n",
      "Accuracy: 45.0 %\n",
      "Epoch 15/30, Loss: 1.4522\n",
      "Accuracy: 45.0 %\n",
      "Epoch 16/30, Loss: 1.4459\n",
      "Accuracy: 45.0 %\n",
      "Epoch 17/30, Loss: 1.2255\n",
      "Accuracy: 45.0 %\n",
      "Epoch 18/30, Loss: 1.6408\n",
      "Accuracy: 45.0 %\n",
      "Epoch 19/30, Loss: 1.7224\n",
      "Accuracy: 45.0 %\n",
      "Epoch 20/30, Loss: 1.4744\n",
      "Accuracy: 45.0 %\n",
      "Epoch 21/30, Loss: 1.5367\n",
      "Accuracy: 45.0 %\n",
      "Epoch 22/30, Loss: 1.7397\n",
      "Accuracy: 45.0 %\n",
      "Epoch 23/30, Loss: 1.4902\n",
      "Accuracy: 45.0 %\n",
      "Epoch 24/30, Loss: 1.3605\n",
      "Accuracy: 45.0 %\n",
      "Epoch 25/30, Loss: 1.9442\n",
      "Accuracy: 45.0 %\n",
      "Epoch 26/30, Loss: 1.6711\n",
      "Accuracy: 45.0 %\n",
      "Epoch 27/30, Loss: 1.5960\n",
      "Accuracy: 45.0 %\n",
      "Epoch 28/30, Loss: 2.0403\n",
      "Accuracy: 45.0 %\n",
      "Epoch 29/30, Loss: 1.5982\n",
      "Accuracy: 45.0 %\n",
      "Epoch 30/30, Loss: 1.7590\n",
      "Accuracy: 45.0 %\n"
     ]
    }
   ],
   "source": [
    "train(cnn_gru, train_dataloader, test_dataloader, 30, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model failure\n",
    "As can be observed, the model does not converge, and both the accuracy on the test set and the loss from the training set are roughly constant.\n",
    "\n",
    "This is likely because the model is too complex, and suffers from over-fitting. As can be seen in the cell below, the model outputs the same prediction for any input, likely because it is just outputting the mostly common class from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 0\n",
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 3\n",
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 4\n",
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 3\n",
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 3\n",
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 3\n",
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 2\n",
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 0\n",
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 3\n",
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 1\n",
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 0\n",
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 0\n",
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 6\n",
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 0\n",
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 0\n",
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 0\n",
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 0\n",
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 3\n",
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 3\n",
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 6\n",
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 0\n",
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 0\n",
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 3\n",
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 0\n",
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 3\n",
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 0\n",
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 0\n",
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 0\n",
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 6\n",
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 3\n",
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 0\n",
      "tensor([[0.9989, 0.0266, 0.0014, 0.6137, 0.0022, 0.0020, 0.0038]],\n",
      "       grad_fn=<SigmoidBackward0>) 0\n"
     ]
    }
   ],
   "source": [
    "for i in  range(32):\n",
    "    dat, lab = validate[i]\n",
    "    dat = torch.tensor(dat)\n",
    "    dat = dat.unsqueeze(1).reshape([1, 1, 70, -1])\n",
    "    print(cnn_gru(dat), lab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "50.039_Deep_Learning-cPAezcP5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
